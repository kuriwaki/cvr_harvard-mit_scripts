---
title: "CVR Export formats"
author: "Shiro Kuriwaki"
date: today
format: 
  html:
    self-contained: true
---

The purpose of this memo is to give prototypes of how we will store the CVR data. What columns do we store for the Dataverse release of partisan offices? What format? What is the best format for size, usability, and replicability?

**Tentative Takeaways**: We may be able to save all our counties' data on congress + president + state leg in a 100-200MB .feather file? 

# Example

```{r}
#| echo: false
#| include: false

library(tidyverse)
library(arrow)
library(gt)

dat_full <- read_feather("data-harvard/samp-release_full.feather")
dat <- read_feather("data-harvard/samp-release.feather")


```

I will use a sample of 10 counties and five offices.

The counties are:

```{r}
#| echo: false
dat |> 
  summarize(
    n_voters = sum(contest == "US_PRES"),
    .by = c(state, county)
            ) |>
  arrange(state, county) |> 
  gt() |> 
  gt::fmt_integer(n_voters)
```

The offices are:

```{r}
#| echo: false
dat |> 
  count(contest) |> 
  gt()
```

In total, this represents `r dat |> filter(contest == "US_PRES") |> distinct(state, county, cvr_id) |> nrow() |> format(big.mark = ",")` voters. Our Presidential vote count tabulated 374 counties covering 54 million presidential votes. So, the 10 counties used here serve as roughly a 1% sample.

# Long formats

tldr: After separating things into mini-tables to avoid duplication, I found that a duplicated table was fine for size purposes (skip to the end).

The full Snyder et al. data contains information like the following

```{r}
dat_full
```

These are a lot of variables. The "database"-oriented way to think about this would be to sever these into mini tables, where each table represents a unique key-value pair.

For example, all we need to retain the individual nature of the CVR is:

```{r}
votes <- dat_full |> 
  distinct(county_fips, cvr_id, column, choice_id)
votes
```

where `cvr_id` uniquely defines a CVR record within `county_fips`, `column` is a non-unique indicator for the contest, and `choice_id` is a value for the choice. This naming is idiosyncratic, but the "column" notation makes it easier to link the data to the original cvr download.

To make the barebones `voters` table useful, we have a "contests" table defined by

```{r}
contests <- dat_full |> 
  distinct(county_fips, column, contest, dist) |> 
  arrange(desc(county_fips))
```

```{r}
contests
```

This shows that , for example, in county 39091, column 4 of the cvr file is for President, column 5 is for US Rep., and so on. We also know the district-level variables here, like the district of the House/State House rep.

Next, we can have a "candidates" table defined by

```{r}
cands <- dat_full |> 
  distinct(county_fips, column, choice_id, choice, party)
```

```{r}
cands
```

This shows that choice_id 2 in county 6027, column 9 is Joe Biden. And we know that Joe Biden is a Democrat.

Finally, we also can have counties table

```{r}
dat_full |> 
  distinct(state, county_name, county_fips)
```

I thought saving all these tables a lot of space. However, the stripped `votes` table was 10MB in feather format (described below), whereas the following somewhat more expressive table

```{r}
dat
```

is actually 10.5MB! This might owe in large part to the way feather organizes files. The same data is 6MB in a zipped csv file.

# Wide formats

The most logical format to show the value of the CVR data is "wide" format where each row is a voter. The reshape from long to wide is easy with R's `pivot_wider` as long as the number of contests is not too large.

Limiting ourselves to states where the state legislatures are votefor=1 offices, we can do this as `pivot_wider(dat, names_from = contest, values_from = party)` .

One issue in practice when doing this is that we get errors where there are often more than one row per cvr_id. This happens for example in the Inyo, CA dataset where sometimes there are over 50 rows per cvr_id. To fix this, we arbitrarily pick one.

```{r}
dat_deduped <- dat |>
  tidylog::distinct(state, county, cvr_id, contest, .keep_all = TRUE)
```

With this, we could run

```{r}
dat_deduped |> 
  pivot_wider(
    id_cols = c(state, county, cvr_id),
    names_from = contest,
    values_from = c(party)) |> 
  sample_frac()
```

Problems with this format: This does not store the district of the voter. That mean we don't know if empty cells are undervotes/overvotes or where there was "no election".

The user can join this dataset by `c("state", "county", "cvr_id")` to get the relevant districts.

# File Format

What format should the data be saved in? I looked at the read and write times and memory of the following options:

-   csv, zipped into csv.gz
-   Stata .dta
-   feather

| File type     | File Size | Read time | Write time |
|---------------|-----------|-----------|------------|
| csv.gz        | 7 MB      | 1.1s      | 0.8 sec    |
| Stata .dta    | 75.2 MB   | 6.0s      | 1.8 sec    |
| arrow feather | 10.5 MB   | 0.6s      | 0.6 sec    |

: Output format: csv vs. dta vs. feather

For Stata and feather, I turned all character variables into factors. That helped decrease the file size by 2x in Stata and about 10% in feather. so that e.g. "JOE BIDEN" is encoded once in a number, and we do not need to store that character string millions of times.

From this, it looks like the arrow feather format is the best: it is the fastest to read and write. The file size is somewhat larger than
